{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "#https://www.openml.org/d/37\n",
        "#Pima Indians Diabetes Database\n",
        "diabetes = fetch_openml(name='diabetes',  as_frame=True)\n",
        "print(diabetes.frame.columns)\n",
        "print(diabetes.frame.describe())\n",
        "print(diabetes.details)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PRc1EOi1LHj",
        "outputId": "684bb153-1d44-481b-dcdf-97d2b988db46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age', 'class'], dtype='object')\n",
            "             preg        plas        pres        skin        insu        mass  \\\n",
            "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
            "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
            "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
            "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
            "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
            "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
            "\n",
            "             pedi         age  \n",
            "count  768.000000  768.000000  \n",
            "mean     0.471876   33.240885  \n",
            "std      0.331329   11.760232  \n",
            "min      0.078000   21.000000  \n",
            "25%      0.243750   24.000000  \n",
            "50%      0.372500   29.000000  \n",
            "75%      0.626250   41.000000  \n",
            "max      2.420000   81.000000  \n",
            "{'id': '37', 'name': 'diabetes', 'version': '1', 'description_version': '3', 'format': 'ARFF', 'creator': 'Peter D. Turney', 'collection_date': '1995-03-01', 'upload_date': '2014-04-06T23:22:13', 'language': 'English', 'licence': 'Public', 'url': 'https://api.openml.org/data/v1/download/37/diabetes.arff', 'parquet_url': 'https://openml1.win.tue.nl/datasets/0000/0037/dataset_37.pq', 'file_id': '37', 'default_target_attribute': 'class', 'version_label': '1', 'citation': 'https://www.jair.org/index.php/jair/article/view/10129', 'tag': ['Health', 'Medicine', 'mythbusting_1', 'OpenML-CC18', 'OpenML100', 'study_1', 'study_123', 'study_135', 'study_14', 'study_15', 'study_20', 'study_29', 'study_30', 'study_34', 'study_37', 'study_41', 'study_52', 'study_7', 'study_70', 'study_98', 'study_99', 'uci'], 'visibility': 'public', 'original_data_url': 'https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes', 'paper_url': 'https://www.jair.org/index.php/jair/article/view/10129', 'minio_url': 'https://openml1.win.tue.nl/datasets/0000/0037/dataset_37.pq', 'status': 'active', 'processing_date': '2020-11-20 18:49:43', 'md5_checksum': '3cbaa3e54586aa88cf6aacb4033e4470'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:301: UserWarning: Multiple active versions of the dataset matching the name diabetes exist. Versions may be fundamentally different, returning version 1.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get rid of any rown with NA's\n",
        "diabetes.frame = diabetes.frame.dropna()"
      ],
      "metadata": {
        "id": "vaDy4cb9R4VH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW76pPxuXJ6V",
        "outputId": "4a0b23cb-ad6f-4091-fd9c-a663cc31891c"
      },
      "source": [
        "#from sklearn.datasets import fetch_openml\n",
        "#load mice protein dataset from OpenML\n",
        "#mice = fetch_openml(name='miceprotein', version=4, as_frame=True)\n",
        "#list(mice.frame.columns)\n",
        "#print(mice.details)\n",
        "#mice.frame.describe()\n",
        "\n",
        "\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Import model to divide data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import onehotencoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "target_column = ['class']\n",
        "#dropping target column for onehot encoding\n",
        "predictorsdroptarget = diabetes.frame.drop(columns=target_column)\n",
        "# Apply OneHotEncoder to categorical variables\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "# fit and transoformed data\n",
        "predictors = encoder.fit_transform(predictorsdroptarget)\n",
        "print(predictors)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the input data\n",
        "X = predictors\n",
        "#the output data\n",
        "y = diabetes.frame['class']\n",
        "\n",
        "#we encode target classes from strings to numbers as neural networks cannot require all numerical inputs and outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "#divide data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "print(X_train.shape); print(X_test.shape)\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(decision_function_shape='ovo')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "#We predict the training set\n",
        "predict_train = svm_model.predict(X_train)\n",
        "#we predict the test set\n",
        "predict_test = svm_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "print('Training accuracy')\n",
        "#we report the confusion matrix for the training set\n",
        "print(confusion_matrix(y_train,predict_train))\n",
        "#we report various accuracy statistics for the training set\n",
        "print(classification_report(y_train,predict_train))\n",
        "\n",
        "print('Testing accuracy')\n",
        "#we report the confusion matrix for the test set\n",
        "print(confusion_matrix(y_test,predict_test))\n",
        "#we report various accuracy statistics for the test set\n",
        "print(classification_report(y_test,predict_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCKUGANgQqt2",
        "outputId": "3091a6a0-72be-4311-e354-87b73b2c8430"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(537, 1246)\n",
            "(231, 1246)\n",
            "Training accuracy\n",
            "[[338   0]\n",
            " [ 14 185]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       338\n",
            "           1       1.00      0.93      0.96       199\n",
            "\n",
            "    accuracy                           0.97       537\n",
            "   macro avg       0.98      0.96      0.97       537\n",
            "weighted avg       0.97      0.97      0.97       537\n",
            "\n",
            "Testing accuracy\n",
            "[[156   6]\n",
            " [ 61   8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82       162\n",
            "           1       0.57      0.12      0.19        69\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.65      0.54      0.51       231\n",
            "weighted avg       0.67      0.71      0.63       231\n",
            "\n"
          ]
        }
      ]
    }
  ]
}